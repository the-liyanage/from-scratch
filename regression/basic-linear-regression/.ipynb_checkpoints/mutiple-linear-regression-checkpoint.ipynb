{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3a0f5e8-6787-4d6e-b755-2d90ee2e0e00",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression From Scratch \n",
    "\n",
    "### OOP Concepts Covered:\n",
    " 1. Class - Blueprint for objects\n",
    " 2. Constructor `(__init__)` - Initialize object state\n",
    " 3. Attributes - Data stored in the object\n",
    " 4. Methods - Functions that operate on object data\n",
    " 5. Encapsulation - Bundling data and methods together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd81771-a6ba-4652-b32d-3bb47bf6dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e45bc7cd-8bb9-496b-8e4f-6be958a6d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleLinearRegression:\n",
    "    \"\"\"\n",
    "    Multiple Linear Regression Model\n",
    "\n",
    "    Formula: y = w1*x1 + w2*x2 + ..... + wn*xn + b\n",
    "\n",
    "    Example: House Price = w1*Size + w2*Bedrooms + w3*Age + b\n",
    "\n",
    "    This class represents ONE regression model.\n",
    "    Each model has its own weights, bias and training history.\n",
    "    \"\"\"\n",
    "    #Constructor - Called when you create a new model\n",
    "    #eg: model = MultipleLinearRegression(learning_rate = 0.01)\n",
    "\n",
    "    def __init__(self, learning_rate = 0.01, iterations = 1000):\n",
    "        \"\"\"\n",
    "        Initialize a new regression model.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        learning_rate : float (default = 0.01)\n",
    "            How big each step is during gradient descent.\n",
    "            - Too large : Model might not converge (diverge)\n",
    "            - Too small : Training takes forever\n",
    "            - Typical values: 0.001 to 0.01\n",
    "\n",
    "\n",
    "        iterations: int (default = 1000)\n",
    "            Number of times to update the weights during training.\n",
    "                - More iterations = more learning time\n",
    "                - Usually 100 to 10,000 depending on problem\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Attribute: Store learning rate for later use\n",
    "        #'self' means 'this specific object'\n",
    "        #self.lr means 'this object's learning rate'\n",
    "        self.lr = learning_rate\n",
    "        self.iterations = iterations\n",
    "\n",
    "        #Attribute: Weights (one for each feature)\n",
    "        #Initially None, will be filled during training.\n",
    "        #eg: [150,200,5660] for [size, bedrooms, age]\n",
    "        self.weights = None\n",
    "\n",
    "        #Attruibute: Bias (intercept term)\n",
    "        #the base value when all the features are 0\n",
    "        self.bias = 0\n",
    "\n",
    "        #Attribute: Training history\n",
    "        #We'll store cost at each iteration to track progress\n",
    "        self.history = []\n",
    "\n",
    "        #Attribute: Nummber of features (columns in X)\n",
    "        #Will be set during training \n",
    "        self.n_features = None\n",
    "\n",
    "        #Attribute: Flag to check if model is trained \n",
    "        self.is_trained = False\n",
    "\n",
    "        print(f\"Learning Rate: {self.lr}\")\n",
    "        print(f\"Iterations: {self.iterations}\")\n",
    "\n",
    "    #--------------------------------------------------------\n",
    "    #train the mode\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the model using gradient descent.\n",
    "\n",
    "        Parameters:\n",
    "        X : lists of lists\n",
    "            Training features, shape (n_samples, n_features)\n",
    "            Eg: [[1500, 4, 6 ], --> House 1: size, beds, age\n",
    "                 [2000, 6, 10], --> House 2\n",
    "                 [3400, 8, 3]]  --> House 3\n",
    "\n",
    "        y: list\n",
    "            Target values, shape (n_samples)\n",
    "            Eg: [30000,40000,34000] --> Prices\n",
    "\n",
    "\n",
    "        What this does:\n",
    "        1. Initialize weights and bias to zero\n",
    "        2. Repeat for 'iterations\" times:\n",
    "         - Calculate predictions\n",
    "         - Calculate error (How wrong we are)\n",
    "         - Calculate gradients (which direction to adjust)\n",
    "         - Update weights and bias (take a step)\n",
    "        3. Store cost history for visualization\n",
    "\n",
    "        \"\"\"\n",
    "        #Get dimensions of data\n",
    "        #m - number of training examples (rows)\n",
    "        m = len(X)\n",
    "        #count the number of features in the House 1 (assuming all houses have same number of features)\n",
    "        #n - number of features (columns)\n",
    "        n = len(X[0]) \n",
    "        self.n_features = n\n",
    "        print(f\"Training samples: {m}\")\n",
    "        print(f\"Features: {n}\")\n",
    "\n",
    "        #Initialize weights to zero (one weight per feature)\n",
    "        #Eg: [0, 0, 0] for 3 features \n",
    "        self.weights = [0.0] * n\n",
    "        self.bias = 0.0\n",
    "\n",
    "        print(f\"Initial weights: {self.weights}\")\n",
    "        print(f\"Initial bias: {self.bias}\")\n",
    "        print(\"\\nStarting gradient descent.. \\n\")\n",
    "\n",
    "\n",
    "        #Gradient Descent Loop\n",
    "        for iteration in range(self.iterations):\n",
    "            #--------------------------------------------- (01)\n",
    "            #Forward pass (make predictions)\n",
    "            #For each training example, calculate prediction \n",
    "            #prediciton = w1*x1 + w2*x2 + ... + wn*xn + b\n",
    "            predictions = []\n",
    "\n",
    "            for i in range(m): #For each house\n",
    "                #Calculate: prediction = sum(weight * feature) + b\n",
    "                prediction = self.bias #Start with bias\n",
    "\n",
    "                for j in range(n): #for each feature\n",
    "                    #Add (weights[j] * feature[j])\n",
    "                    prediction += self.weights[j] * X[i][j]\n",
    "                predictions.append(prediction)\n",
    "\n",
    "        #--------------------------------------------------- (02)\n",
    "        #Calculate cost (how wrong we are)\n",
    "        #Cost = Mean Squared Error (MSE)\n",
    "        #MSE = (1/m) * sum(prediction - actual)^2\n",
    "\n",
    "        total_squared_error = 0.0\n",
    "        for i in range(m):\n",
    "            error = predictions[i] - y[i]\n",
    "            squared_error = error **2\n",
    "            total_squared_erro += squared_error\n",
    "        cost = total_squared_error/m\n",
    "\n",
    "\n",
    "        #Store cost for visualization \n",
    "        self.cost_history.append(cost)\n",
    "\n",
    "        #------------------------------------------------ (03)\n",
    "        #Calculate Gradients (Which directions to move)\n",
    "        #Gradient tells us how to adjust weights to reduce cost\n",
    "\n",
    "        #Math Behind it:\n",
    "        # ∂Cost/∂w[j] = (1/m) * sum((prediction - actual) * x[j])\n",
    "        # ∂Cost/∂b = (1/m) * sum(prediction - actual)\n",
    "\n",
    "        #Initialize gradient for weights (one per feature)\n",
    "        gradients_w = [0.0] * n\n",
    "        #Initialize gradient for bias \n",
    "        gradient_b = 0.0\n",
    "\n",
    "        #Calculate gradients\n",
    "        for i in range(m):\n",
    "            error = predicitons[i] - y[i]\n",
    "\n",
    "            #Gradient for each weight\n",
    "            for j in range(m): #for each feature\n",
    "                gradients_w[j] += error * x[i][j]\n",
    "\n",
    "            #Gradient for bias\n",
    "            gradient_b += error\n",
    "\n",
    "        #Average the gradients (divide by m)\n",
    "        for j in range(n):\n",
    "            gradients_w[j] = gradients_w[j]/m\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57862aca-fbd8-4f34-a47c-7a6a07992823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
